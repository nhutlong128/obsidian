---
cards-deck: Obsidian::Cloud-Computing::Storage::S3
tags: s3, storage
---
### Metadata

-  Type: #permanent #storage
    Date written: #2021-05-17
    Source:  
    Status: #wip 
    Keywords:  #cloudcomputing #aws #s3
	References: [[S3 - Literature]]
	Related:
	
### Notes
- [[S3 Storage Type]]
- [[S3 Provision Instance]]
- [[S3 Location]]
- [[S3 Type]]
- [[S3 High Availability Mechanism]]
- [[S3 Scalability Mechanism]]
- [[S3 Security]]
- [[S3 Replication]]
- [[S3 Optimize]]
- [[S3 Fees charged]] (Not Done)
- [[S3 Specific]]


### Questions

1. You're trying to upload a 25 GB file on S3 and it's not working
- The file size limit on S3 is 5GB
- The S3 service must down
- You should use Multi Part upload when you file is bigger than 5GB
#card 
You should use Multi Part upload when you file is bigger than 5GB
^1626791065285

2. I tried creating an S3 bucket named "dev" but it didn't work. This is a new AWS Account and I have no buckets at all. What is the cause?
- I'm missing IAM permissions to create a bucket
- Bucket names must be globally unique and "dev" is already taken
#card 
Bucket names must be globally unique and "dev" is already taken
^1626791065296

3. You've added files in your bucket and then enabled versioning. The files you've already added will have which version?
- 1
- 0
- -1
- null
#card 
null
^1626791065307

4. Your client wants to make sure the encryption is happening in S3, but wants to fully manage the encryption keys and never store them in AWS. You recommend
- SSE - S3
- SSE - KMS
- SSE - C
- Client Side Encryption
#card 
SSE - C. Here you have full control over the encryption keys, and let AWS do the encryption
^1626791065318

5. Your company wants data to be encrypted in S3, and maintain control of the rotation policy for the encryption keys, but not know the encryption keys values. You recommend
- SSE - S3
- SSE - KMS
- SSE - C
- Client Side Encryption
#card 
With SSE-KMS you let AWS manage the encryption keys but you have full control of the key rotation policy
^1626791065330

6. Your company does not trust S3 for encryption and wants it to happen on the application. You recommend
- SSE - S3
- SSE - KMS
- SSE - C
- Client Side Encryption
#card 
With Client Side Encryption you perform the encryption yourself and send the encrypted data to AWS directly. AWS does not know your encryption keys and cannot decrypt your data.
^1626791065340

7. The bucket policy allows our users to read/write files in the bucket, yet we were not able to perform a PutObject API call.
- The bucket policy must be wrong
- The IAM user must have an explicit DENY in the attached IAM policy
- You need to contact AWS Support to lift this limit
#card 
The IAM user must have an explicit DENY in the attached IAM policy
^1626791065351

8. You have a website that loads files from another S3 bucket. When you try the URL of the files directly in your Chrome browser it works, but when the website you're visiting tries to load these files it doesn't. What's the problem?
- The Bucket policy is wrong
- The IAM policy is wrong
- CORS is wrong
- Encryption is wrong
#card 
CORS is wrong. Cross-origin resource sharing (CORS) defines a way for client web applications that are loaded in one domain to interact with resources in a different domain.
^1626791065362

9. You have enabled versioning and want to be extra careful when it comes to deleting files on S3. What should you enable to prevent accidental permanent deletions?
- Use bucket policy
- Enable MFA Delete
- Encrypt the files
- Disable Versioning
#card 
MFA Delete forces users to use MFA tokens before deleting objects. It's an extra level of security to prevent accidental deletes
^1626791065373

10. You would like all your files in S3 to be encrypted by default. What is the optimal way of achieving this?
- Use a bucket policy that forces HTTPS connections
- Enable Default Encryption on S3
- Enable Versioning
#card 
Enable Default Encryption on S3
^1626791065384

11. You suspect some of your employees to try to access files in S3 that they don't have access to. How can you verify this is indeed the case without them noticing?
- Restrict their IAM Policies and look at CloudTrail logs
- Enable S3 Access Logs and analyze them using Athena
- Use a bucket policy
#card 
S3 Access Logs log all the requests made to buckets, and Athena can then be used to run serverless analytics on top of the logs files
^1626791065395

12. You are looking for your entire S3 bucket to be available fully in a different region so you can perform data analysis optimally at the lowest possible cost. Which feature should you use?
- CloudFront distributions
- S3 Cross Region Replication
- S3 Versioning
- S3 Websites
#card 
S3 CRR is used to replicate data from an S3 bucket to another one in a different region
^1626791065406

13. You are looking to provide temporary URLs to a growing list of federated users in order to allow them to perform a file upload on S3 to a specific location. What should you use?
- S3 CORS
- S3 Pre-Signed Url
- S3 Bucket Policies
- IAM Users
#card 
Pre-Signed URL are temporary and grant time-limited access to some actions in your S3 bucket.
^1626791065416

14. How can you automate the transition of S3 objects between their different tiers?
- AWS Lambda
- Use Cloudwatch Events
- Use S3 Lifecycles
#card 
Use S3 Lifecycles
^1626791065427

15. Which of the following is NOT a Glacier retrieval mode?
- Instant (10 seconds)
- Expedited (1 to 5 minutes)
- Standard (3 to 5 hours)
- Bulk (5 to 12 hours)
Instant (10 seconds)

16. Which of the following is a Serverless data analysis service allowing you to query data in S3?
- S3 Analytics
- Athena
- Redshift
- RDS
#card 
Athena
^1626791065438

17. You are looking to build an index of your files in S3, using Amazon RDS PostgreSQL. To build this index, it is necessary to read the first 250 bytes of each object in S3, which contains some metadata about the content of the file itself. There is over 100,000 files in your S3 bucket, amounting to 50TB of data. how can you build this index efficiently?
- Use the RDS Import feature to load the data from S3 to PostgreSQL, and run a SQL query to build the index
- Create an application that will traverse the S3 bucket, read all the files one by one, extract the first 250 bytes, and store that information in RDS.
- Create an application that will traverse the S3 bucket, issue a Byte Range Fetch for the first 250 bytes, and store that information in RDS.
- Create an application that will traverse the S3 bucket, use S3 select to get the first 250 bytes, and store that information in RDS.
#card 
Create an application that will traverse the S3 bucket, issue a Byte Range Fetch for the first 250 bytes, and store that information in RDS.
^1626791065449

18. A media company produces new video files on-premises every day with a total size of around 100GB after compression. All files have a size of 1-2 GB and need to be uploaded to Amazon S3 every night in a fixed time window between 3am and 5am. Current upload takes almost 3 hours, although less than half of the available bandwidth is used. What step(s) would ensure that the file uploads are able to complete in the allotted time window?  
a. Increase your network bandwidth to provide faster throughput to S3  
b. Upload the files in parallel to S3 using multipart upload  
c. Pack all files into a single archive, upload it to S3, then extract the files in AWS  
d. Use AWS Import/Export to transfer the video files
#card 
B
^1626791065459

19. You are designing a web application that stores static assets in an Amazon Simple Storage Service (S3) bucket. You expect this bucket to immediately receive over 150 PUT requests per second. What should you do to ensure optimal performance?  
A. Use multi-part upload.  
B. Add a random prefix to the key names.  
C. Amazon S3 will automatically manage performance at this scale.  
D. Use a predictable naming scheme, such as sequential numbers or date time sequences, in the key names
#card 
B
^1626791065470

20. You have an application running on an Amazon Elastic Compute Cloud instance, that uploads 5 GB video objects to Amazon Simple Storage Service (S3). Video uploads are taking longer than expected, resulting in poor application performance. Which method will help improve performance of your application?  
A. Enable enhanced networking  
B. Use Amazon S3 multipart upload  
C. Leveraging Amazon CloudFront, use the HTTP POST method to reduce latency.  
D. Use Amazon Elastic Block Store Provisioned IOPs and use an Amazon EBS-optimized instance
#card 
B
^1626791065481

21. Which of the following methods gives you protection against accidental loss of data stored in Amazon S3? (Choose 2)  
A Set bucket policies to restrict deletes, and also enable versioning  
B. By default, versioning is enabled on a new bucket so you don't have to worry about it (Not enabled by default)  
C. Build a secondary index of your keys to protect the data (improves performance only)  
D. Back up your bucket to a bucket owned by another AWS account for redundancy
#card 
A, D
^1626791065491

22. What does Amazon S3 stand for?  
A. Simple Storage Solution.  
B. Storage Storage Storage (triple redundancy Storage).  
C. Storage Server Solution.  
D. Simple Storage Service
#card 
D
^1626791065502

23. What are characteristics of Amazon S3? Choose 2 answers  
A. Objects are directly accessible via a URL  
B. S3 should be used to host a relational database  
C. S3 allows you to store objects or virtually unlimited size  
D. S3 allows you to store virtually unlimited amounts of data  
E. S3 offers Provisioned IOPS
#card 
A, D
^1626791065513

24. You are building an automated transcription service in which Amazon EC2 worker instances process an uploaded audio file and generate a text file. You must store both of these files in the same durable storage until the text file is retrieved. You do not know what the storage capacity requirements are. Which storage option is both cost-efficient and scalable?  
A. Multiple Amazon EBS volume with snapshots  
B. A single Amazon Glacier vault  
C. A single Amazon S3 bucket  
D. Multiple instance stores
#card 
C
^1626791065524

25. A user wants to upload a complete folder to AWS S3 using the S3 Management console. How can the user perform this activity?  
A. Just drag and drop the folder using the flash tool provided by S3  
B. Use the Enable Enhanced Folder option from the S3 console while uploading objects  
C. The user cannot upload the whole folder in one go with the S3 management console  
D. Use the Enable Enhanced Uploader option from the S3 console while uploading objects
#card 
D
^1626791065535

26. A company is deploying a two-tier, highly available web application to AWS. Which service provides durable storage for static content while utilizing lower Overall CPU resources for the web tier?  
A. Amazon EBS volume  
B. Amazon S3  
C. Amazon EC2 instance store  
D. Amazon RDS instance
#card 
B
^1626791065546

27. You have an application running on an Amazon Elastic Compute Cloud instance, that uploads 5 GB video objects to Amazon Simple Storage Service (S3). Video uploads are taking longer than expected, resulting in poor application performance. Which method will help improve performance of your application?  
A. Enable enhanced networking  
B. Use Amazon S3 multipart upload  
C. Leveraging Amazon CloudFront, use the HTTP POST method to reduce latency.
D. Use Amazon Elastic Block Store Provisioned IOPs and use an Amazon EBS-optimized instance
#card 
B
^1626791065556

28. When you put objects in Amazon S3, what is the indication that an object was successfully stored?  
A. Each S3 account has a special bucket named_s3_logs. Success codes are written to this bucket with a timestamp and checksum.  
B. A success code is inserted into the S3 object metadata.  
C. A HTTP 200 result code and MD5 checksum, taken together, indicate that the operation was successful.  
D. Amazon S3 is engineered for 99.999999999% durability. Therefore there is no need to confirm that data was inserted.
#card 
C
^1626791065567

29. You have private video content in S3 that you want to serve to subscribed users on the Internet. User IDs, credentials, and subscriptions are stored in an Amazon RDS database. Which configuration will allow you to securely serve private content to your users?  
A. Generate pre-signed URLs for each user as they request access to protected S3 content  
B. Create an IAM user for each subscribed user and assign the GetObject permission to each IAM user  
C. Create an S3 bucket policy that limits access to your private content to only your subscribed users' credentials  
D. Create a CloudFront Origin Identity user for your subscribed users and assign the GetObject permission to this user
#card 
A
^1626791065578

30. You run an ad-supported photo sharing website using S3 to serve photos to visitors of your site. At some point you find out that other sites have been linking to the photos on your site, causing loss to your business. What is an effective method to mitigate this?  
A. Remove public read access and use signed URLs with expiry dates.  
B. Use CloudFront distributions for static content.  
C. Block the IPs of the offending websites in Security Groups  
D. Store photos on an EBS volume of the web server.
#card 
A
^1626791065589

31. You are designing a web application that stores static assets in an Amazon Simple Storage Service (S3) bucket. You expect this bucket to immediately receive over 150 PUT requests per second. What should you do to ensure optimal performance?  
A. Use multi-part upload.  
B. Add a random prefix to the key names.  
C. Amazon S3 will automatically manage performance at this scale.  
D. Use a predictable naming scheme, such as sequential numbers or date time sequences, in the key names
#card 
B
^1626791065599

32. What is the maximum number of S3 buckets available per AWS Account?  
A. 100 Per region  
B. There is no Limit  
C. 100 Per Account  
D. 500 Per Account  
E. 100 Per IAM User
#card 
C
^1626791065610

33. What does RRS stand for when talking about S3?  
A. Redundancy Removal System  
B. Relational Rights Storage  
C. Regional Rights Standard  
D. Reduced Redundancy Storage
#card 
D
^1626791065620

34. What is the durability of S3 RRS?  
A. 99.99%  
B. 99.95%  
C. 99.995%  
D 99.999999999%
#card 
A
^1626791065631

35. What is the Reduced Redundancy option in Amazon S3?  
A. Less redundancy for a lower cost  
B. It doesn't exist in Amazon S3, but in Amazon EBS.  
C. It allows you to destroy any copy of your files outside a specific jurisdiction.
D. It doesn't exist at all
#card 
A
^1626791065642

36. An application is generating a log file every 5 minutes. The log file is not critical but may be required only for verification in case of some major issue. The file should be accessible over the internet whenever required. Which of the below mentioned options is a best possible storage solution for it?  
A. AWS S3  
B. AWS Glacier  
C. AWS RDS  
D. AWS S3 RRS
#card 
D
^1626791065653

37. A user has moved an object to Glacier using the life cycle rules. The user requests to restore the archive after 6 months. When the restore request is completed the user accesses that archive. Which of the below mentioned statements is not true in this condition?  
A. The archive will be available as an object for the duration specified by the user during the restoration request  
B. The restored object's storage class will be RRS  
C. The user can modify the restoration period only by issuing a new restore request with the updated period  
D. The user needs to pay storage for both RRS (restored) and Glacier (Archive) Rates
#card 
B
^1626791065664

38. A company is storing data on Amazon Simple Storage Service (S3). The company's security policy mandates that data is encrypted at rest. Which of the following methods can achieve this? Choose 3 answers  
A. Use Amazon S3 server-side encryption with AWS Key Management Service managed keys  
B. Use Amazon S3 server-side encryption with customer-provided keys  
C. Use Amazon S3 server-side encryption with EC2 key pair.  
D. Use Amazon S3 bucket policies to restrict access to the data at rest.  
E. Encrypt the data on the client-side before ingesting to Amazon S3 using their own master key  
F. Use SSL to encrypt the data while in transit to Amazon S3.
#card 
A, B, E
^1626791065675

39. A user has enabled versioning on an S3 bucket. The user is using server side encryption for data at Rest. If the user is supplying his own keys for encryption (SSE-C) which of the below mentioned statements is true?  
A. The user should use the same encryption key for all versions of the same object  
B. It is possible to have different encryption keys for different versions of the same object 
C. AWS S3 does not allow the user to upload his own keys for server side encryption 
D The SSE-C does not work when versioning is enabled
#card 
B
^1626791065686

40. A storage admin wants to encrypt all the objects stored in S3 using server side encryption. The user does not want to use the AES 256 encryption key provided by S3. How can the user achieve this?  
A. The admin should upload his secret key to the AWS console and let S3 decrypt the objects  
B. The admin should use CLI or API to upload the encryption key to the S3 bucket. When making a call to the S3 API mention the encryption key URL in each request  
C. S3 does not support client supplied encryption keys for server side encryption  
D. The admin should send the keys and encryption algorithm with each API call
#card 
D
^1626791065697

41. A user has enabled versioning on an S3 bucket. The user is using server side encryption for data at rest. If the user is supplying his own keys for encryption (SSE-C), what is recommended to the user for the purpose of security?  
A. User should not use his own security key as it is not secure  
B. Configure S3 to rotate the user's encryption key at regular intervals  
C. Configure S3 to store the user's keys securely with SSL  
D. Keep rotating the encryption key manually at the client side
#card 
D
^1626791065708

42. A system admin is planning to encrypt all objects being uploaded to S3 from an application. The system admin does not want to implement his own encryption algorithm; instead he is planning to use server side encryption by supplying his own key (SSE-C.. Which parameter is not required while making a call for SSE-C?  
A. x-amz-server-side-encryption-customer-key-AES-256  
B. x-amz-server-side-encryption-customer-key  
C. x-amz-server-side-encryption-customer-algorithm  
D. x-amz-server-side-encryption-customer-key-MD5
#card 
A
^1626791065719

43. A customer is leveraging Amazon Simple Storage Service in eu-west-1 to store static content for a web-based property. The customer is storing objects using the Standard Storage class. Where are the customers objects replicated?  
A. A single facility in eu-west-1 and a single facility in eu-central-1  
B. A single facility in eu-west-1 and a single facility in us-east-1  
C. Multiple facilities in eu-west-1  
D. A single facility in eu-west-1
#card 
C
^1626791065730

44. Which features can be used to restrict access to data in S3? Choose 2 answers  
A. Set an S3 ACL on the bucket or the object.  
B. Create a CloudFront distribution for the bucket.  
C. Set an S3 bucket policy.  
D. Enable IAM Identity Federation  
E. Use S3 Virtual Hosting
#card 
A, C
^1626791065740

45. Which method can be used to prevent an IP address block from accessing public objects in an S3 bucket?  
A. Create a bucket policy and apply it to the bucket  
B. Create a NACL and attach it to the VPC of the bucket  
C. Create an ACL and apply it to all objects in the bucket  
D. Modify the IAM policies of any users that would access the bucket
#card 
A
^1626791065750

46. A user has granted read/write permission of his S3 bucket using ACL. Which of the below mentioned options is a valid ID to grant permission to other AWS accounts (grantee. using ACL?  
A. IAM User ID  
B. S3 Secure ID  
C. Access ID  
D. Canonical user ID
#card 
D
^1626791065762

47. A root account owner has given full access of his S3 bucket to one of the IAM users using the bucket ACL. When the IAM user logs in to the S3 console, which actions can he perform?  
A. He can just view the content of the bucket  
B. He can do all the operations on the bucket  
C. It is not possible to give access to an IAM user using ACL  
D. The IAM user can perform all operations on the bucket using only API/SDK
#card 
C
^1626791065774

48. A root AWS account owner is trying to understand various options to set the permission to AWS S3. Which of the below mentioned options is not the right option to grant permission for S3?  
A. User Access Policy  
B. S3 Object Policy  
C. S3 Bucket Policy  
D. S3 ACL
#card 
B
^1626791065784

49. A system admin is managing buckets, objects and folders with AWS S3. Which of the below mentioned statements is true and should be taken in consideration by the sysadmin?  
A. Folders support only ACL  
B. Both the object and bucket can have an Access Policy but folder cannot have policy  
C. Folders can have a policy  
D. Both the object and bucket can have ACL but folders cannot have ACL
#card 
D
^1626791065795

50. A user has created an S3 bucket which is not publicly accessible. The bucket is having thirty objects which are also private. If the user wants to make the objects public, how can he configure this with minimal efforts?  
A. User should select all objects from the console and apply a single policy to mark them public  
B. User can write a program which programmatically makes all objects public using S3 SDK  
C. Set the AWS bucket policy which marks all objects as public  
D. Make the bucket ACL as public so it will also mark all objects as public
#card 
C
^1626791065806

51. You need to configure an Amazon S3 bucket to serve static assets for your public-facing web application. Which methods ensure that all objects uploaded to the bucket are set to public read? Choose 2 answers  
A. Set permissions on the object to public read during upload.  
B. Configure the bucket ACL to set all objects to public read.  
C. Configure the bucket policy to set all objects to public read.  
D. Use AWS Identity and Access Management roles to set the bucket to public read.  
E. Amazon S3 objects default to public read, so no action is needed.
#card 
A, C
^1626791065817

52. Amazon S3 doesn't automatically give a user who creates _____ permission to perform other actions on that bucket or object.  
A. a file  
B. a bucket or object  
C. a bucket or file  
D. a object or file
#card 
B
^1626791065827

53. A root account owner is trying to understand the S3 bucket ACL. Which of the below mentioned options cannot be used to grant ACL on the object using the authorized predefined group?  
A. Authenticated user group  
B. All users group  
C. Log Delivery Group  
D. Canonical user group
#card 
D
^1626791065838

54. Your firm has uploaded a large amount of aerial image data to S3. In the past, in your on-premises environment, you used a dedicated group of servers to oaten process this data and used Rabbit MQ, an open source messaging system, to get job information to the servers. Once processed the data would go to tape and be shipped offsite. Your manager told you to stay with the current design, and leverage AWS archival storage and messaging services to minimize cost. Which is correct?  
A. Use SQS for passing job messages, use Cloud Watch alarms to terminate EC2 worker instances when they become idle. Once data is processed, change the storage class of the S3 objects to Reduced Redundancy Storage  
B. Setup Auto-Scaled workers triggered by queue depth that use spot instances to process messages in SQS. Once data is processed, change the storage class of the S3 objects to Reduced Redundancy Storage  
C. Setup Auto-Scaled workers triggered by queue depth that use spot instances to process messages in SQS. Once data is processed, change the storage class of the S3 objects to Glacier  
D. Use SNS to pass job messages use Cloud Watch alarms to terminate spot worker instances when they become idle. Once data is processed, change the storage class of the S3 object to Glacier.
#card 
C
^1626791065849

55. You have a proprietary data store on-premises that must be backed up daily by dumping the data store contents to a single compressed 50GB file and sending the file to AWS. Your SLAs state that any dump file backed up within the past 7 days can be retrieved within 2 hours. Your compliance department has stated that all data must be held indefinitely. The time required to restore the data store from a backup is approximately 1 hour. Your on-premise network connection is capable of sustaining 1gbps to AWS. Which backup methods to AWS would be most cost-effective while still meeting all of your requirements?  
A. Send the daily backup files to Glacier immediately after being generated  
B. Transfer the daily backup files to an EBS volume in AWS and take daily snapshots of the volume  
C. Transfer the daily backup files to S3 and use appropriate bucket lifecycle policies to send to Glacier  
D. Host the backup files on a Storage Gateway with Gateway-Cached Volumes and take daily snapshots
#card 
C
^1626791065860

56. Which set of Amazon S3 features helps to prevent and recover from accidental data loss?  
A. Object lifecycle and service access logging  
B. Object versioning and Multi-factor authentication  
C. Access controls and server-side encryption  
D. Website hosting and Amazon S3 policies
#card 
B
^1626791065870

57. You use S3 to store critical data for your company Several users within your group currently have full permissions to your S3 buckets. You need to come up with a solution that does not impact your users and also protect against the accidental deletion of objects. Which two options will address this issue? Choose 2 answers  
A. Enable versioning on your S3 Buckets  
B. Configure your S3 Buckets with MFA delete  
C. Create a Bucket policy and only allow read only permissions to all users at the bucket level  
D. Enable object life cycle policies and configure the data older than 3 months to be archived in Glacier
#card 
A, B
^1626791065881

58. To protect S3 data from both accidental deletion and accidental overwriting, you should  
A. enable S3 versioning on the bucket  
B. access S3 data using only signed URLs  
C. disable S3 delete using an IAM bucket policy  
D. enable S3 Reduced Redundancy Storage  
E. enable Multi-Factor Authentication (MFA) protected access
#card 
A
^1626791065891

59. Object limit in buckets of S3?
#card 
No Limit
^1626791065902

60. 403 Error of S3?
#card 
Forbidden
^1626791065913

61. 400 Error of S3?
#card 
400 Error
^1626791065924

62. 409 Error of S3
#card 
Conflict
^1626791065935

63. 500 Error of S3
#card 
Internal Server Error
^1626791065946

64. What's the min. and max. size of a file in S3?
#card 
0/5 Tb
^1626791065956

65. What is the data consistency model for S3?
#card 
- Read after Write consistency for PUTS of new objects.  
- Eventual consistency for overwrite PUTS and DELETES (can take some time to propagate).
^1626791065967

66. Can you remove versioning after you have activated it to a bucket S3?
#card 
No, but you can suspend it (disable it).
^1626791065978

67. Do I need to give permissions again to a file if I re-upload it S3?
#card 
Only if versioning is active for the bucket where the file is put.
^1626791065988

68. In lifecycle management, what are the storage classes involved?
#card 
S3, Infrequent Access, Glacier and Deletion.
^1626791065999

69. Can I give lifecycle management to a specific file?
#card 
No. You can give it to the whole bucket or to subfolders of it.
^1626791066010

70. In lifecycle management, what's the minimum amount of days that an object can be in S3 - Infrequent Access Storage Class before transitioning to the Glacier Storage Class?
#card 
30 days
^1626791066021

71. What kind of AWS resources can be Origin Servers for CloudFront?
#card 
S3 Bucket, EC2 instance, ELB or Route53.
^1626791066031

72. For how long are objects cached in an Edge Location?
#card 
For the TTL of the objects there.
^1626791066042

73. Can I clear cached objects in my edge locations?
#card 
Yes, but you will be charged.
^1626791066053

74. What is Transfer Acceleration?
#card 
A technology that let users upload or download files in S3 buckets, by using Edge locations from CloudFront. It gives you a new URL location (Endpoint).
^1626791066064

74. Can I use transfer acceleration for a subfolder only?
#card 
No. You can use it for the whole bucket only.
^1626791066074

75. What is CORS for?
#card 
Using CORS (Cross-Origin Resource Sharing) you can selectively allow web applications running on other domains to access content in your Amazon S3 bucket.
^1626791066085

76. What does Cross-Region Replication do?
#card 
It replicates every future upload of every object to another bucket in another region.
^1626791066095

77. What does Cross-Region Replication needs in order to be available?
#card 
That versioning is active in both the source and the destination buckets.
^1626791066106

78. If you encrypt a bucket on S3 what encryption does AWS use?
#card 
Advanced Encryption Standard (AES) 256
^1626791066117

79. What is the largest size file you can transfer to S3 using a PUT operation?
#card 
5Gb. After that you must use a multipart upload.
^1626791066128

80. What can I do If I want to enable a user to download my private data directly from S3?
#card 
If you want to enable a user to download your private data directly from S3, you can insert a pre-signed URL into a web page before giving it to your user. (? See Exam 4: S3 quiz).
^1626791066138

81. What is another name for AWS Snowball?
#card 
AWS Import/export^1626791066149
